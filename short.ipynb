{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCAJnJG3qYm"
      },
      "source": [
        "<h1 align=\"center\">Real Estate Price Prediction</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVO7DnqN3a9x"
      },
      "source": [
        "**This short Notebook correspond to the score 0.16643**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvPjOtE_7DpA"
      },
      "source": [
        "<h1 align=\"center\">LOADING PIPELINE</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQq210zgY_Tr",
        "outputId": "27075292-bfec-4361-945a-19854a58f979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   249  100   249    0     0    294      0 --:--:-- --:--:-- --:--:--   294\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.7.0) (1.19.5)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main_parser.py\", line 8, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/cmdoptions.py\", line 23, in <module>\n",
            "    from pip._internal.cli.parser import ConfigOptionParser\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/parser.py\", line 12, in <module>\n",
            "    from pip._internal.configuration import Configuration, ConfigurationError\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/configuration.py\", line 21, in <module>\n",
            "    from pip._internal.exceptions import (\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/exceptions.py\", line 7, in <module>\n",
            "    from pip._vendor.pkg_resources import Distribution\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 84, in <module>\n",
            "    __import__('pip._vendor.packaging.requirements')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/requirements.py\", line 10, in <module>\n",
            "    from pip._vendor.pyparsing import (  # noqa: N817\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 5677, in <module>\n",
            "    _reBracketExpr = Literal(\"[\") + Optional(\"^\").setResultsName(\"negate\") + Group(OneOrMore(_charRange | _singleChar)).setResultsName(\"body\") + \"]\"\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1467, in setResultsName\n",
            "    def setResultsName(self, name, listAllMatches=False):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.7/dist-packages (0.14.2)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2.5.0)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.8.2)\n",
            "Requirement already satisfied: distributed<2021.07,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2021.6.2)\n",
            "Requirement already satisfied: smac>=0.14 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.10.0.2)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.0.0)\n",
            "Requirement already satisfied: dask<2021.07 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2021.6.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.7.2)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: pynisher>=0.6.3 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.6.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.19.5)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.4.20)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (3.0.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.24)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (0.11.2)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (2021.11.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask<2021.07->auto-sklearn) (1.2.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask<2021.07->auto-sklearn) (0.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Requirement already satisfied: emcee>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from smac>=0.14->auto-sklearn) (3.1.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed<2021.07,>=2.2.0->auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy) (1.52)\n",
            "Requirement already satisfied: haversine in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.2)\n",
            "Requirement already satisfied: pipelineprofiler in /usr/local/lib/python3.7/dist-packages (0.1.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pipelineprofiler) (1.19.5)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from pipelineprofiler) (5.3.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pipelineprofiler) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pipelineprofiler) (0.24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pipelineprofiler) (1.7.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from pipelineprofiler) (2.8.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (5.1.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (5.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (4.10.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (4.9.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (5.3.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (0.12.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->pipelineprofiler) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook->pipelineprofiler) (22.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->pipelineprofiler) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->pipelineprofiler) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook->pipelineprofiler) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->pipelineprofiler) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->pipelineprofiler) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->pipelineprofiler) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->pipelineprofiler) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->pipelineprofiler) (0.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->pipelineprofiler) (2.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->pipelineprofiler) (21.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->pipelineprofiler) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook->pipelineprofiler) (3.0.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pipelineprofiler) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pipelineprofiler) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install\n",
        "\n",
        "!pip install auto-sklearn\n",
        "!pip install scipy\n",
        "!pip install seaborn\n",
        "!pip install geopy\n",
        "!pip install haversine\n",
        "!pip install lightgbm\n",
        "!pip install xgboost\n",
        "!pip install pipelineprofiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKgGtTNw-QAY"
      },
      "source": [
        "Data storage :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPAzK74TmnIX",
        "outputId": "eed86cad-9161-4658-b882-ebd2d57c13d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmmT7XgHvsu1"
      },
      "source": [
        "We are using external data in addition to the data provided in kaggle, this links contains a folder DATA with all csv files needed to reproduce our prediction (the folder is also provided on BLACKBOARD as a zip file):\n",
        "\n",
        "https://drive.google.com/drive/folders/1-4z5G7FYxyJrqBjG9cHiiBi5Z2ZjuNVV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6cAsUNJZnYwu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno  # For missing data visualization\n",
        "from google.colab import files\n",
        "from geopy.distance import distance\n",
        "from haversine import haversine, haversine_vector, Unit\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "import autosklearn.metrics\n",
        "import autosklearn.pipeline.components.regression\n",
        "from autosklearn.regression import AutoSklearnRegressor\n",
        "from autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm\n",
        "\n",
        "import PipelineProfiler   # For auto-sklearn model interpretation  \n",
        "\n",
        "np.random.seed(123)\n",
        "sns.set_style('darkgrid')\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "# We are using a folder data provided by link and on blackboard\n",
        "data_filepath = './drive/MyDrive/data/' \n",
        "pd.options.display.max_columns = None # Be careful using this with one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lbCFuxQonrHt"
      },
      "outputs": [],
      "source": [
        "apartments = pd.read_csv(data_filepath + 'apartments_train.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BNPeThiBnt0E"
      },
      "outputs": [],
      "source": [
        "buildings = pd.read_csv(data_filepath + 'buildings_train.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNT-I8lh8mrO"
      },
      "source": [
        "Merge apartments and buildings in the same dataframe :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xdzzwku3n2UF"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kRu9Gr0poAxs"
      },
      "outputs": [],
      "source": [
        "apartments_test = pd.read_csv(data_filepath + 'apartments_test.csv')\n",
        "buildings_test = pd.read_csv(data_filepath + 'buildings_test.csv')\n",
        "\n",
        "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='left', left_on='building_id', right_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1usDmgh7p6nQ"
      },
      "outputs": [],
      "source": [
        "ap_test_id = apartments_test['id']\n",
        "ap_bu_train_id = apartments['building_id']\n",
        "ap_bu_test_id = apartments_test['building_id']\n",
        "bu_train_id = buildings['id']\n",
        "bu_test_id = buildings_test['id']\n",
        "\n",
        "n_ap_train = apartments.shape[0]\n",
        "n_ap_test = apartments_test.shape[0]\n",
        "n_bu_train = buildings.shape[0]\n",
        "n_bu_test = buildings_test.shape[0]\n",
        "\n",
        "y_train = apartments.price.values\n",
        "\n",
        "all_ap = pd.concat((apartments, apartments_test)).reset_index(drop=True)\n",
        "all_bu = pd.concat((buildings, buildings_test)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZkV3EVq2qDuQ"
      },
      "outputs": [],
      "source": [
        "all_data = pd.merge(all_ap, all_bu.set_index('id'), how='left', left_on='building_id', right_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2__RXqM91Y99"
      },
      "source": [
        "<h1 align=\"center\">PREPROCESSING PIPELINE</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3poBad_HqN32"
      },
      "outputs": [],
      "source": [
        "all_ap.drop(['price'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEadVmj64EBa"
      },
      "source": [
        "Fill some obvious "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wEjPjt8EqT3S"
      },
      "outputs": [],
      "source": [
        "all_bu['latitude'] = all_bu['latitude'].fillna(55.5675811)\n",
        "all_bu['longitude'] = all_bu['longitude'].fillna(37.48152684)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kovp7daQqb4y"
      },
      "outputs": [],
      "source": [
        "all_bu['elevator_without'] = all_bu['elevator_without'].replace(np.NaN, all_bu['elevator_without'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_SVGUg66qdOj"
      },
      "outputs": [],
      "source": [
        "all_data = pd.merge(all_ap, all_bu.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
        "\n",
        "all_data.drop('id', axis=1, inplace=True)\n",
        "all_data.drop('building_id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jbC7rYd0qhK-"
      },
      "outputs": [],
      "source": [
        "street_dict = {}\n",
        "def convert_to_int(street):\n",
        "    if street in street_dict: return street_dict[street]\n",
        "    integer = len(street_dict.keys())\n",
        "    street_dict[street] = integer\n",
        "    return integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z5uQRP8Rqi_z"
      },
      "outputs": [],
      "source": [
        "all_bu['ordinal_street'] = np.array([convert_to_int(word) for word in all_bu['street']])  # Useful for feature engineering, i.e. groupby()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX4IL2kJ4Jgg"
      },
      "source": [
        "Correct some obvious wrong values for the location based on the real location on google maps :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kxfF9aIDqo2i"
      },
      "outputs": [],
      "source": [
        "all_bu.at[6973, 'latitude'] = 55.63384636810666\n",
        "all_bu.at[6973, 'longitude'] = 37.41986901627135\n",
        "\n",
        "all_bu.at[7899, 'latitude'] = 55.54371958666631\n",
        "all_bu.at[7899, 'longitude'] = 37.48233889847151\n",
        "\n",
        "all_bu.at[9061, 'latitude'] = 55.62773817227544\n",
        "all_bu.at[9061, 'longitude'] = 37.46499797519564\n",
        "\n",
        "all_bu.at[9512, 'latitude'] = 55.80920516603121\n",
        "all_bu.at[9512, 'longitude'] = 37.34990449848708\n",
        "\n",
        "all_bu.at[9629, 'latitude'] = 55.54371958666631\n",
        "all_bu.at[9629, 'longitude'] = 37.48233889847151"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBuT4tmY4Soa"
      },
      "source": [
        "**FEATURE GENERATION**\n",
        "\n",
        "Create new useful features such as the distance to points of interests (e.g, train tram or subways stations or park to relax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HyEqtiehqwi6"
      },
      "outputs": [],
      "source": [
        "all_bu['coordinates'] = list(zip(all_bu['latitude'], all_bu['longitude']))\n",
        "\n",
        "def get_min_distance(feature_name):\n",
        "  feature = pd.read_csv(f'{data_filepath}{feature_name}.csv', dtype='float64')\n",
        "  feature['coordinates'] = list(zip(feature['latitude'], feature['longitude']))\n",
        "\n",
        "  bu_coord = all_bu['coordinates'].to_numpy(copy=True).tolist()\n",
        "  feature_coord = feature['coordinates'].to_numpy(copy=True).tolist()\n",
        "\n",
        "  distances = haversine_vector(bu_coord, feature_coord, unit=Unit.KILOMETERS, comb=True)\n",
        "\n",
        "  distances_frame = pd.DataFrame(data=distances)\n",
        "  feature_min = pd.DataFrame({f'{feature_name}_min': distances_frame.min(axis=0)})\n",
        "  feature_min.to_csv(f'{data_filepath}{feature_name}_min.csv', index=False)\n",
        "  all_bu[f'{feature_name}_min'] = feature_min\n",
        "\n",
        "get_min_distance('subway')\n",
        "get_min_distance('train')\n",
        "get_min_distance('tram')\n",
        "get_min_distance('park')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl06Abm15Fhg"
      },
      "source": [
        "New feature transit: minimum distance to a facility/infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KzIZ2QFNqzXg"
      },
      "outputs": [],
      "source": [
        "all_bu['transit_min'] = all_bu[['subway_min', 'train_min', 'tram_min']].min(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xdiU8YB5Wla"
      },
      "source": [
        "New feature radius : the distance from an apartment to the \"center\" of the city"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MroTzCAwq1TX"
      },
      "outputs": [],
      "source": [
        "latitude_mean = all_bu['latitude'].mean(axis=0, skipna=True)\n",
        "longitude_mean = all_bu['longitude'].mean(axis=0, skipna=True)\n",
        "latitude_kremlin = 55.75202223    # Dist, to kremlin yields lower correlation than mean\n",
        "longitude_kremlin = 37.61749837\n",
        "\n",
        "difference_latitude = all_bu['latitude'] - latitude_mean\n",
        "difference_longitude = all_bu['longitude'] - longitude_mean\n",
        "radius = pd.DataFrame({\"radius\":np.sqrt(np.square(difference_latitude) + np.square(difference_longitude))})\n",
        "\n",
        "middle = (latitude_mean, longitude_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_krBtytzq2vm"
      },
      "outputs": [],
      "source": [
        "radius = all_bu['coordinates'].apply(lambda x: distance(x, middle))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4RfcewHLq4vI"
      },
      "outputs": [],
      "source": [
        "radius = radius.astype(str).str[:-3].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z3yWGfA8rAZy"
      },
      "outputs": [],
      "source": [
        "all_bu['radius'] = pd.DataFrame({\"radius\":radius})\n",
        "all_bu['closeness'] = 1 / np.sqrt(radius)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d1KM_Ny5nUZ"
      },
      "source": [
        "The data engineering has been made for some features related to the buildings (the distance for a subway station is the same for all the apartments in the same building), now It will be done for features directly related to the apartments : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRnGPktMrDHo",
        "outputId": "8856d12b-674c-47ad-90d9-4e14320eb8a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "# Getting new test and train sets:\n",
        "\n",
        "apartments = all_ap[:n_ap_train]\n",
        "apartments['price'] = y_train         # train set\n",
        "# apartments.drop(index=2804, inplace=True)\n",
        "# apartments.drop(index=15840, inplace=True)\n",
        "# apartments.drop(index=21414, inplace=True)\n",
        "apartments_test = all_ap[n_ap_train:] # number in train\n",
        "\n",
        "buildings = all_bu[:n_bu_train]\n",
        "buildings_test = all_bu[n_bu_train:]\n",
        "\n",
        "data = pd.merge(apartments, buildings.set_index('id'), how='inner', left_on='building_id', right_index=True)\n",
        "data_y = data['price']\n",
        "data_x = data.drop(['price'], axis=1)\n",
        "\n",
        "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='inner', left_on='building_id', right_index=True)\n",
        "\n",
        "n_train = data.shape[0]\n",
        "all_data = pd.concat((data, data_test)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-ElGTtg3rFxu"
      },
      "outputs": [],
      "source": [
        "compressed_floor = all_data.groupby(['building_id'])['floor'].transform(lambda x: x - x.min())\n",
        "compressed_stories = all_data.groupby(['building_id'])['floor'].transform(lambda x: x.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yK7s0IPBrHhL"
      },
      "outputs": [],
      "source": [
        "all_data['stairs_to_walk'] = pd.DataFrame({\"stairs_to_walk\": 1 / ((1 - all_data['elevator_without'])* (compressed_stories - compressed_floor) + 1)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5KujmPilrJYI"
      },
      "outputs": [],
      "source": [
        "all_data['kegness'] = all_data['area_total'] / all_data['radius']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7X3eWhSGrLOr"
      },
      "outputs": [],
      "source": [
        "all_data['seller'] = all_data['seller'].astype('category')\n",
        "all_data['layout'] = all_data['layout'].astype('category')\n",
        "all_data['condition'] = all_data['condition'].astype('category')\n",
        "all_data['district'] = all_data['district'].astype('category')\n",
        "all_data['street'] = all_data['street'].astype('category')\n",
        "all_data['address'] = all_data['address'].astype('category')\n",
        "all_data['material'] = all_data['material'].astype('category')\n",
        "all_data['parking'] = all_data['parking'].astype('category')\n",
        "all_data['heating'] = all_data['heating'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8w6reROYrM3M"
      },
      "outputs": [],
      "source": [
        "data = all_data[:n_train]\n",
        "data_test = all_data[n_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OH7kcsLmrPC9"
      },
      "outputs": [],
      "source": [
        "final_train = data.drop(['id', 'building_id', 'street', 'ordinal_street', 'address', 'coordinates', 'tram_min', 'train_min', 'subway_min'], axis=1) # 'windows_court', 'phones', 'new'\n",
        "final_test = data_test.drop(['id', 'building_id', 'street', 'ordinal_street', 'address', 'coordinates', 'tram_min', 'train_min', 'subway_min'], axis=1) # 'windows_court', 'phones', 'new'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76gZtZ76BFXO"
      },
      "source": [
        "Our features are one-hot encoded "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "94nLo9EYrRPC"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded_training_predictors = pd.get_dummies(final_train)\n",
        "one_hot_encoded_test_predictors = pd.get_dummies(final_test)\n",
        "\n",
        "final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n",
        "                                                                    join='inner', \n",
        "                                                                    axis=1)\n",
        "final_test.drop(['price'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "corOgSZbDxhN"
      },
      "source": [
        "Then the target is log transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EFldtO6XrZCA"
      },
      "outputs": [],
      "source": [
        "final_train['price'] = np.log(final_train['price'])\n",
        "data_y = np.log(data_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkjfKhwBD2s0"
      },
      "source": [
        "We drop the price since it's our target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_t6sDolHrqwE"
      },
      "outputs": [],
      "source": [
        "final_train.drop(['price'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs9J9JgQFef6"
      },
      "source": [
        "<h1 align=\"center\">MODEL FITTING</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42VEx6HYD5TX"
      },
      "source": [
        "Our best model was achieved using the following configuration #\n",
        "\n",
        "\n",
        "*   A training time of 2 hours\n",
        "*   RMSE as the metric to optimize since the target is log transformed\n",
        "*   Cross-validation with a fold of 5 \n",
        "*   Default parameters of the AutoSklearnRegressor method : we are training an ensemble of 50 differents models and fine-tuning is handled by the library\n",
        "*   Moreover, the imputation of missing values is included in the method\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AWQ2DiTgtIjV"
      },
      "outputs": [],
      "source": [
        "training_time = 60 * 60 * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IkeEEomNrhOD"
      },
      "outputs": [],
      "source": [
        "auto_regr = AutoSklearnRegressor(time_left_for_this_task= training_time, \n",
        "                                 metric=autosklearn.metrics.root_mean_squared_error,\n",
        "                                 resampling_strategy='cv',\n",
        "                                 resampling_strategy_arguments={'folds':5},\n",
        "                                 seed=41)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFt6fRDfrnyL",
        "outputId": "8198506e-a958-402c-ea98-54dcd382295c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AutoSklearnRegressor(metric=root_mean_squared_error, per_run_time_limit=720,\n",
              "                     resampling_strategy='cv',\n",
              "                     resampling_strategy_arguments={'folds': 5}, seed=41,\n",
              "                     time_left_for_this_task=7200)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auto_regr.fit(final_train, data_y, dataset_name='Moscow Housing Kaggle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KYhPydlTtAMU"
      },
      "outputs": [],
      "source": [
        "auto_regr_predictions = auto_regr.predict(final_test)\n",
        "auto_regr_predictions = np.exp(auto_regr_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JF11_Sl1tDHZ"
      },
      "outputs": [],
      "source": [
        "prediction_frame = pd.DataFrame(columns={'id': data_test['id'], 'price_prediction': auto_regr_predictions})\n",
        "prediction_frame['id'] = data_test['id']\n",
        "prediction_frame['price_prediction'] = auto_regr_predictions\n",
        "prediction_frame.to_csv(f'{data_filepath}prediction/finalprediction_{training_time / 60}_mins.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yyNDp7HtE4K"
      },
      "outputs": [],
      "source": [
        "files.download(f'{data_filepath}prediction/finalprediction_{training_time / 60}_mins.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "short_jupyter_notebook_Group41.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
